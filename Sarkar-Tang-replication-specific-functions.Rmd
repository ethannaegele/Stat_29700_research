---
title: "Sarkar and Tang specific functions"
author: "Ethan Naegele"
date: "2024-04-28"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(knockoff)
library(pracma)
library(tidyverse)
```


# Functions specific to quantities from Sarkar and Tang

```{r}
# faster function for calculating norm of vector
norm_vec <- function(x) sqrt(sum(x^2))

# obtain the unbiased estimator of the variance parameter tau in the regression setting Y = N(X * beta, tau^2 I_n)
get_variance_parameter_estimate <- function(X, Y){
  n <- nrow(X)
  d <- ncol(X)
  # Ensure Y is a vector and has appropriate length
  #if (!is.vector(Y) || length(Y) != nrow(X)) {
   # stop("Y must be a vector and match the number of rows in X")
 # }
  
  # Convert X to a data frame
  df_X <- as.data.frame(X)
  
  # Add Y to the dataframe
  df_X$Y <- Y
  
  # Fit the model using the formula
  model <- lm(Y ~ ., data=df_X)
  residuals_sum_sq <- deviance(model)
  return(sqrt(residuals_sum_sq / (n - d)))
}
```






```{r}
# get the T_1  estimate provided at the beginning of section 2
# SQRTM USES THE PRACMA VERSION HERE CURRENTLY
get_T_1 <- function(X, Y){
  sigma <- t(X) %*% X
  D <- diag(create.solve_equi(sigma)) # need to turn the output into a diagonal matrix
  X_ko <- create.fixed(X, method = 'equi')$Xk
  beta_hat_1 <- solve(2 * sigma - D) %*% t(X + X_ko) %*% Y
  # tau hat estimated with the columnwise concatenation of X and knockoff X
  T_1 <- (1 / (get_variance_parameter_estimate(cbind(X, X_ko), Y) * sqrt(2))) *
    sqrtm(diag(diag(solve(2 * sigma - D))))$Binv %*% beta_hat_1 # unsure about interpretation of diag operator in the equation for T1 from the paper; this is my best interpretation of it - Ignat agrees. Binv returns the inverse of the square root that sqrtm calculates, which is what the formula requires. 
  # The formula in the paper shows we invert 2 sigma - D first, then diag, but that is giving no power. If we 
  # diag first then invert, it works but fdr is roughly twice alpha with high power. 
  return(T_1)
  #return(rcond(2 * sigma - D))
}

# get the T_2 estimate 
get_T_2 <- function(X, Y){
  D <- diag(create.solve_equi(t(X) %*% X))
  X_ko <- create.fixed(X, method = 'equi')$Xk
  beta_hat_2 <- solve(D) %*% t(X - X_ko) %*% Y
  T_2 <- (1 / (get_variance_parameter_estimate(cbind(X, X_ko), Y) * sqrt(2))) * sqrtm(D)$B %*% beta_hat_2
  return(T_2)
}

```



```{r}
get_regression_model <- function(n, d, a, num_true_signals, random_true_signal_indices = FALSE){
  # random_true_signal_indices selects which indices will be true signals randomly
  # n = sample size, ie number of rows in the matrix
  # d = number of features
  # a = signal strength
  # num_true_signals = number of nonzero beta coefficients
  # Returns an X matrix, response Y, and the positions of the true signals, as according to the simulation setup described in the beginning of Section 3 of Sarkar and Tang
  rho <- 0.5
   cor_matrix <- matrix(nrow = d, ncol = d)
for (i in 1:d) {
  for (j in 1:d) {
    cor_matrix[i, j] <- rho^abs(i - j)
  }
}

# Perform Cholesky decomposition of the correlation matrix
cholesky_factor <- chol(cor_matrix)

# Generate independent standard normal variables
random_normals <- matrix(rnorm(n * d), nrow = n, ncol = d)

# Transform the independent normals using the Cholesky factor to get correlated normals
X <- random_normals %*% cholesky_factor

X <- normc(X, center = F) # X must be normalized to get sensible values from the knockoff functions. Here using the normalizing function used internally in the package

if (random_true_signal_indices){
  nonzero_indices <- sample(d, num_true_signals) # randomly sample some indices to be the true signal indices
  beta_true <- a * (1:d %in% nonzero_indices) # all the other positions in the vector will be 0
}
else{
  nonzero_indices <- 1:num_true_signals
  beta_true <- c(rep(a, times = num_true_signals), rep(0, times = d - num_true_signals))
}

Y <- X %*% beta_true + rnorm(n) # linear regression model

return(list('X' = X, 'Y' = Y, 'nonzero_indices' = nonzero_indices))
}
```


```{r}
get_regression_model(n = 100, d = 10, a = 2, num_true_signals = 1)
```


```{r}
sarkar_tang_method1 <- function(X, Y, alpha){
  d <- ncol(X)
  nu <- nrow(X) - 2 * d # n - 2d assuming n > 2d
  T1 <- get_T_1(X, Y)
  T2 <- get_T_2(X, Y)
  P_t1 <- pf(T1^2, 1, nu, lower.tail = FALSE) # to calculate probabilities with the t^2_n distribution, have to use the F(1, n) distribution
  P_t2 <- pf(T2^2, 1, nu, lower.tail = FALSE)
  P_tilde <- numeric(d)
  for (j in 1:d){
    if (P_t1[j] > sqrt(alpha)){
      P_tilde[j] <- 1
    }
    else{
      P_tilde[j] <- P_t2[j]
    }
  }
  P_tilde_BH <- p.adjust(P_tilde, method = "BH")
  rejected_indices <- which(P_tilde_BH <= sqrt(alpha))
  return(rejected_indices) # the indices of the features that the test concludes are nonzero
  
}
```


```{r}
# Sarkar and Tang method 1 attempt
set.seed(12)
num_iterations <- 300
fdp_vec <- numeric(num_iterations)
pwr_vec <- c(num_iterations)
for (m in 1:num_iterations){
  num_true_signals <- 8
  d <- 40
  feature_indices <- 1:d
  regression <- get_regression_model(n = 200, d = d, a = 8, num_true_signals = num_true_signals)
  true_nonzero_indices <- regression$nonzero_indices
  rejected_indices <- sarkar_tang_method1(regression$X, regression$Y, alpha = .05)
  num_rejections <- length(rejected_indices)
  num_correct_rejections <- length(intersect(rejected_indices, true_nonzero_indices))
  num_false_rejections <- length(intersect(feature_indices[-true_nonzero_indices], rejected_indices))
  fdp_vec[m] <- num_false_rejections / max(num_rejections, 1)
  pwr_vec[m] <- num_correct_rejections / max(true_nonzero_indices, 1)
}
fdr <- mean(fdp_vec)
pwr <- mean(pwr_vec)
fdr
pwr
```


```{r}
condition_number_test_sdp <- function(X){
  sigma <- t(X) %*% X
  D <- diag(create.solve_sdp(sigma))
  return(rcond(2 * sigma - D))
}
```

```{r}
condition_number_test_equi <- function(X){
  sigma <- t(X) %*% X
  D <- diag(create.solve_equi(sigma))
  return(rcond(2 * sigma - D))
}
```

```{r}
# testing the condition number obtained from using the multiplier version of equicorrelated knockoffs
condition_number_test_equi_mult <- function(X, multiplier = 2){
  sigma <- t(X) %*% X
  D <- create_equicorrelated_mult(X, multiplier = multiplier)$D
  return(rcond(2 * sigma - D))
}
```



# BH using the independent vector only 


using $\hat{\beta}_2$ only


```{r}
independent_BH <- function(X, Y, alpha = .05){
  nu <- nrow(X) - 2 * ncol(X)
  T2 <- get_T_2(X, Y)
  P <- pf(T2^2, 1, nu, lower.tail = FALSE)
  P_BH <- p.adjust(P, method = "BH")
  rejected_indices <- which(P_BH <= alpha)
  return(rejected_indices) # the indices of the features that the test concludes are nonzero
}
```


```{r}
# independent BH attempt (ie, only using beta_hat2)
set.seed(12)
num_iterations <- 300
fdp_vec <- numeric(num_iterations)
pwr_vec <- c(num_iterations)
for (m in 1:num_iterations){
  num_true_signals <- 8
  d <- 40
  feature_indices <- 1:d
  regression <- get_regression_model(n = 200, d = d, a = 8, num_true_signals = num_true_signals)
  true_nonzero_indices <- regression$nonzero_indices
  rejected_indices <- independent_BH(regression$X, regression$Y, alpha = .05)
  num_rejections <- length(rejected_indices)
  num_correct_rejections <- length(intersect(rejected_indices, true_nonzero_indices))
  num_false_rejections <- length(intersect(feature_indices[-true_nonzero_indices], rejected_indices))
  fdp_vec[m] <- num_false_rejections / max(num_rejections, 1)
  pwr_vec[m] <- num_correct_rejections / max(true_nonzero_indices, 1)
}
fdr <- mean(fdp_vec)
pwr <- mean(pwr_vec)
fdr
pwr
```


```{r}
# independent BH attempt (ie, only using beta_hat2)
set.seed(12)
num_iterations <- 300
fdp_vec <- numeric(num_iterations)
pwr_vec <- c(num_iterations)
for (m in 1:num_iterations){
  num_true_signals <- 8
  d <- 40
  feature_indices <- 1:d
  regression <- get_regression_model(n = 200, d = d, a = 6, num_true_signals = num_true_signals)
  true_nonzero_indices <- regression$nonzero_indices
  rejected_indices <- independent_BH(regression$X, regression$Y, alpha = .05)
  num_rejections <- length(rejected_indices)
  num_correct_rejections <- length(intersect(rejected_indices, true_nonzero_indices))
  num_false_rejections <- length(intersect(feature_indices[-true_nonzero_indices], rejected_indices))
  fdp_vec[m] <- num_false_rejections / max(num_rejections, 1)
  pwr_vec[m] <- num_correct_rejections / max(true_nonzero_indices, 1)
}
fdr <- mean(fdp_vec)
pwr <- mean(pwr_vec)
fdr
pwr
```

```{r}
run_method1_simulation <- function(n, d, a, num_true_sigs, num_iter = 300){
  # Sets up the regression problem with specified dimensions and number of true signals, all of which have
  # the same amplitude. 
  fdp_vec <- numeric(num_iter)
pwr_vec <- c(num_iter)
for (m in 1:num_iter){
  feature_indices <- 1:d
  regression <- get_regression_model(n = n, d = d, a = a, num_true_signals = num_true_sigs)
  true_nonzero_indices <- regression$nonzero_indices
  rejected_indices <- sarkar_tang_method1(regression$X, regression$Y, alpha = .05)
  num_rejections <- length(rejected_indices)
  num_correct_rejections <- length(intersect(rejected_indices, true_nonzero_indices))
  num_false_rejections <- length(intersect(feature_indices[-true_nonzero_indices], rejected_indices))
  fdp_vec[m] <- num_false_rejections / max(num_rejections, 1)
  pwr_vec[m] <- num_correct_rejections / max(true_nonzero_indices, 1)
}
fdr <- mean(fdp_vec)
pwr <- mean(pwr_vec)
return(list(fdr = fdr, power = pwr))
}
```

```{r}
set.seed(12)
run_method1_simulation(n = 200, d = 40, a = 8, num_true_sigs = 8, num_iter = 300)
```

```{r}
run_independent_BH_simulation <- function(n, d, a, num_true_sigs, num_iter = 300){
  # Sets up the regression problem with specified dimensions and number of true signals, all of which have
  # the same amplitude. 
  fdp_vec <- numeric(num_iter)
pwr_vec <- c(num_iter)
for (m in 1:num_iter){
  feature_indices <- 1:d
  regression <- get_regression_model(n = n, d = d, a = a, num_true_signals = num_true_sigs)
  true_nonzero_indices <- regression$nonzero_indices
  rejected_indices <- independent_BH(regression$X, regression$Y, alpha = .05)
  num_rejections <- length(rejected_indices)
  num_correct_rejections <- length(intersect(rejected_indices, true_nonzero_indices))
  num_false_rejections <- length(intersect(feature_indices[-true_nonzero_indices], rejected_indices))
  fdp_vec[m] <- num_false_rejections / max(num_rejections, 1)
  pwr_vec[m] <- num_correct_rejections / max(true_nonzero_indices, 1)
}
fdr <- mean(fdp_vec)
pwr <- mean(pwr_vec)
return(list(fdr = fdr, power = pwr))
}
```



```{r}
set.seed(12)
# running setting 1 as specified in the paper
result_vec_power_independent_BH <- c()
result_vec_fdr_independent_BH <- c()
for (amp in c(2, 4, 6, 8, 10)){
  result <- run_independent_BH_simulation(n = 200,
                                          d = 40,
                                          a = amp, 
                                          num_true_sigs = 8, 
                                          num_iter = 300)
  result_vec_power_independent_BH <- c(result_vec_power_independent_BH, result$power)
  result_vec_fdr_independent_BH <- c(result_vec_fdr_independent_BH, result$fdr)
}

```






```{r}
independent_BH_setting1 <- data.frame(a = c(2, 4, 6, 8, 10), 
                                         power = result_vec_power_independent_BH, 
                                         fdr = result_vec_fdr_independent_BH)
```

```{r}
set.seed(12)
# running setting 2 as specified in the paper
result_vec_power_independent_BH_setting2 <- c()
result_vec_fdr_independent_BH_setting2 <- c()
for (amp in c(2, 4, 6, 8, 10)){
  result <- run_independent_BH_simulation(n = 500,
                                          d = 50,
                                          a = amp, 
                                          num_true_sigs = 10, 
                                          num_iter = 500)
  result_vec_power_independent_BH_setting2 <- c(result_vec_power_independent_BH_setting2, result$power)
  result_vec_fdr_independent_BH_setting2 <- c(result_vec_fdr_independent_BH_setting2, result$fdr)
}

```

```{r}
independent_BH_setting2 <- data.frame(a = c(2, 4, 6, 8, 10), 
                                         power = result_vec_power_independent_BH_setting2, 
                                         fdr = result_vec_fdr_independent_BH_setting2)
```


```{r}
ggplot(independent_BH_setting1, aes(x = a, y = power)) + 
  geom_line(color = 'red') +
  geom_point(shape = 4, color = 'red') + 
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = 'Signal Strength - Amplitude', y = 'Simulated Power', title = 'Setting 1 Results (n = 200, d = 40, k = 8)')
```

```{r}
ggplot(independent_BH_setting1, aes(x = a, y = fdr)) + 
  geom_line(color = 'red') +
  geom_point(shape = 4, color = 'red') + 
  scale_y_continuous(limits = c(0, .15)) +
  labs(x = 'Signal Strength - Amplitude', y = 'Simulated FDR', title = 'Setting 1 Results (n = 200, d = 40, k = 8)')
```




```{r}
ggplot(independent_BH_setting2, aes(x = a, y = power)) + 
  geom_line(color = 'red') +
  geom_point(shape = 4, color = 'red') + 
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = 'Signal Strength - Amplitude', y = 'Simulated Power', title = 'Setting 2 Results (n = 500, d = 50, k = 10)')
```


```{r}
ggplot(independent_BH_setting2, aes(x = a, y = fdr)) + 
  geom_line(color = 'red') +
  geom_point(shape = 4, color = 'red') + 
  scale_y_continuous(limits = c(0, .15)) +
  labs(x = 'Signal Strength - Amplitude', y = 'Simulated FDR', title = 'Setting 2 Results (n = 500, d = 50, k = 10)')
```

